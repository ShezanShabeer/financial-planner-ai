[paths]
train = "data/nlp/corpus/train.spacy"
dev   = "data/nlp/corpus/dev.spacy"

[system]
seed = 42

[nlp]
lang = "en"
pipeline = ["tok2vec","ner"]
batch_size = 128

[components]

[components.tok2vec]
factory = "tok2vec"

[components.tok2vec.model]
@architectures = "spacy.HashEmbedCNN.v2"
pretrained_vectors = null
width = 96
depth = 4
embed_size = 2000
window_size = 1
maxout_pieces = 3

[components.ner]
factory = "ner"

[components.ner.model]
@architectures = "spacy.TransitionBasedParser.v2"
state_type = "ner"
extra_state_tokens = false
hidden_width = 64
maxout_pieces = 2
use_upper = false
nO = null

[components.ner.model.tok2vec]
@architectures = "spacy.Tok2VecListener.v1"
width = 96

[corpora]  # <-- parent must exist (no @readers here)

[corpora.train]
@readers = "spacy.Corpus.v1"
path = ${paths.train}
gold_preproc = false

[corpora.dev]
@readers = "spacy.Corpus.v1"
path = ${paths.dev}
gold_preproc = false

[training]
train_corpus = "corpora.train"
dev_corpus   = "corpora.dev"
dropout = 0.2
max_steps = 2000
eval_frequency = 200
patience = 200
gpu_allocator = "pytorch"
seed = 42

[training.optimizer]
@optimizers = "Adam.v1"
learn_rate = 0.001
beta1 = 0.9
beta2 = 0.999
L2 = 0.0
use_averages = true

[initialize]
vectors = null